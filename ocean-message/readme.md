> 海量数据发送
> 

- 数据存储

首先调用了大数据存储hadoop

hadoop与硬件的RAID不同，hadoop是通过软件，在不同的节点进行备份来冗余数据，达到分布式存储的目的。

hadoop的设计本是为了做大数据计算的可靠性存储。并且hadoop的查询过程是分治思想，就是查询到所有节点的数据，然后组装返回。

我觉得对于所有数据进行全表扫描并不具太多的优势

然后是对于mongodb，在之前没有使用过mongodb，只是了解过，像美团这种骑手的位置信息是使用mongodb来存储的。

其优点是吞吐量高，不过可能存在不准确问题（只记得以前在某个blog看过，具体细节kennel有差异）

 

因此最后的想法依旧是使用分库分表的方式

然后对于数据库，通过三主三从组建为一个小的可靠服务（高可用），然后由多克可靠服务组成一个mysql集群。

v-ip

由于前面的三主三从解决了某库不可用的情况，因此我们只需要引入一致性hash即可（或者直接要）。

根据mysql单表查询的数据峰值是2000w，那么对于一个高可用服务我们分5张表那么就是1亿条数据，那么将16个高可用集群并在一起，那么就是16亿条用户数据。满足要求。

那么怎么让这些集群中的数据id字段是一致的呢？

1. redis自增 2.UUID 3.雪花算法



- 定时发送

然后怎么根据id路由到对应的数据表呢（除此之外还要考虑到扩容造成的影响）

首先基于id取模的方式进行ID路由是绝对不可取的， 因为不支持动态扩容。

1.首先还是想通过在一致性hash，但是一致性hash存在一个问题，当添加新的节点后，虽然大部分节点的id路由没有发生变化，但是任然有小部分的变化了，怎么感知小部分变化的ID是需要考虑的，而且是必须需要解决的， 因为肯定不想原来根据id能够在a节点查询到的数据，但是因为动态加入了新的节点，而导致id现在路由到b节点而查询不到的情况。

2.雪花算法包含时间戳信息，我们可以根据时间戳信息来进行分片，比如有6台机器，那么每天的0-5点的数据分片到0号节点，6-11分片到二号节点... , 但是这样做的一个弊端是明显存在数据分布不均匀的情况，这是我们不想看到的





- 第三方短信接口

然后就是查询到数据后发送短信了

首先肯定不能等待时间到了，先去查数据库，然后再挨个挨个发送的第三方短信平台。

应该先从数据库查询到数据，然后等待到时间直接发送到第三方短信平台。

因此基于此考虑，就出现了延时任务，以及生产者消费者的概念。

为了完成上述需求， 目前的想法是通过消息队列来完成这件事。

先提前将数据从数据库查询出来，然后放入消息队列之中（死信队列）。

然后设置的过期时间，实现延时发送。同时也完成了查询数据库与发送消息模块的结偶。





关于第三方短信，如果说只让一个服务商来发送短信，那么可能出现延迟较高的情况。

为了解决这种情况，应该选用多提供商。

然后为了能够应用能够选择多个新消息服务提供商中的一个进行消息发送，那么应该考虑抽象工厂模式来提供一个统一的消息发送。







# 1.数据库创建

![image-20230827131925385](https://woldier-pic-repo-1309997478.cos.ap-chengdu.myqcloud.com/woldier/2023%2F08%2F19b635de62fafdf34a2ff80645ded744.png)

创建了一张user表. 写入了100W条数据,耗时在1分半

然后通过

```sql
SELECT * FROM `user01`
```

查询数据,将100W条一次数据查询出来的耗时是65s.

![image-20230827132258936](https://woldier-pic-repo-1309997478.cos.ap-chengdu.myqcloud.com/woldier/2023%2F08%2F7f56c9367043dee15c4410ed4cadd8bb.png)





然后我试验了加上分页参数的查询时间(对于查询的条数不同,查询时间不同)

| 数据量 | 时间                 |
| ------ | -------------------- |
| 1000   | 0.739s               |
| 10000  | 1.323s,1.119s,1.196s |
| 20000  | 2.084s,1.716s,1.994s |
| 30000  | 2.844s,3.195,3.431s  |
| 50000  | 3.933s,4.249s        |
| 100000 | 7.211s,7.138s,9.116s |



假设查询到的数据只有id(long类型占8字节),name(16个字节),phone(16个字节)

那么粗略估计一个数据行的大小是40B,那么查询到n行数据那么,需要的内存至少是n*40B

假设有10000条数据 那么所需要的内存大约是 10000 * 40B  = 10000 * 40 / 1024 KB = 10000 * 40 / 1024 / 1024 GB  换算后占用的内存大小约为0.38GB. 因此这里选择10000(一万条数据作为一个batch)



然后是对于数据总数的获取

```sql
SELECT count(*) FROM user01 
```

![image-20230827134248773](https://woldier-pic-repo-1309997478.cos.ap-chengdu.myqcloud.com/woldier/2023%2F08%2Fb603b05ae79abdcfd729905a2aa8d1a3.png)

查询时间非常短

基本不用考虑时间问题.







